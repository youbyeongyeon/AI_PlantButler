# server/app/routes/chat.py
from fastapi import APIRouter, HTTPException
from fastapi.concurrency import run_in_threadpool
from pydantic import BaseModel
from typing import Optional, Deque, Dict, List
from collections import deque
from app.config import settings

# OpenAI ì‚¬ìš© ì—¬ë¶€/í´ë¼ì´ì–¸íŠ¸ ì¤€ë¹„
try:
    from openai import OpenAI
    _openai_available = bool(settings.OPENAI_API_KEY)
except Exception:
    OpenAI = None  # type: ignore
    _openai_available = False

router = APIRouter()

# ---- (ì„ íƒ) ê°„ë‹¨í•œ ì¸ë©”ëª¨ë¦¬ íˆìŠ¤í† ë¦¬: room_id ë³„ ìµœê·¼ Ní„´ ë³´ê´€ ----
_MAX_TURNS = 8  # ìµœê·¼ 8ê°œ ë©”ì‹œì§€ë§Œ ìœ ì§€
_histories: Dict[str, Deque[Dict[str, str]]] = {}

class ChatRequest(BaseModel):
    text: str
    room_id: Optional[str] = None  # í´ë¼ê°€ ë°©ID ë„˜ê¸°ë©´ ëŒ€í™” ë§¥ë½ ìœ ì§€

class ChatResponse(BaseModel):
    reply: str

_SYSTEM_PROMPT = (
    "ë‹¹ì‹ ì€ ì‹ë¬¼ ê´€ë¦¬ ë„ìš°ë¯¸ì…ë‹ˆë‹¤. ì‚¬ìš©ìê°€ ì‹ë¬¼ ê´€ë ¨ ì§ˆë¬¸ì„ í•˜ë©´ "
    "í•µì‹¬ë§Œ ê°„ê²°í•˜ê²Œ í•œêµ­ì–´ë¡œ ë‹µí•˜ê³ , í•„ìš”ì‹œ ê°„ë‹¨í•œ ì²´í¬ë¦¬ìŠ¤íŠ¸/ì£¼ì˜ì‚¬í•­ì„ 2~3ê°œ ì œì‹œí•˜ì„¸ìš”. "
    "ë¶ˆí™•ì‹¤í•˜ë©´ ëª¨ë¥´ëŠ” ë¶€ë¶„ì„ ë¶„ëª…íˆ ë°íˆê³ , ì•ˆì „ì´ìŠˆ(ë…ì„±ì‹ë¬¼/ì‚´ì¶©ì œ ë“±)ëŠ” ì£¼ì˜ ë¬¸êµ¬ë¥¼ í¬í•¨í•˜ì„¸ìš”."
)

def _get_openai_client() -> Optional[OpenAI]:
    if not _openai_available or OpenAI is None:
        return None
    # OPENAI_BASE_URLì„ ì‚¬ìš©í•˜ê³  ì‹¶ìœ¼ë©´ .envì— ì„¤ì •
    if settings.OPENAI_BASE_URL:
        return OpenAI(api_key=settings.OPENAI_API_KEY, base_url=settings.OPENAI_BASE_URL)
    return OpenAI(api_key=settings.OPENAI_API_KEY)

def _push_history(room_id: str, role: str, content: str):
    dq = _histories.setdefault(room_id, deque(maxlen=_MAX_TURNS))
    dq.append({"role": role, "content": content})

def _build_messages(user_text: str, room_id: Optional[str]) -> List[Dict[str, str]]:
    messages: List[Dict[str, str]] = [{"role": "system", "content": _SYSTEM_PROMPT}]
    if room_id and room_id in _histories:
        messages.extend(list(_histories[room_id]))
    messages.append({"role": "user", "content": user_text})
    return messages

async def _llm_reply(user_text: str, room_id: Optional[str]) -> str:
    client = _get_openai_client()
    if not client:
        raise RuntimeError("OpenAI client not available")

    model = settings.OPENAI_MODEL or "gpt-4o-mini"
    messages = _build_messages(user_text, room_id)

    # OpenAI SDK v1ì€ ë™ê¸°ì´ë¯€ë¡œ ìŠ¤ë ˆë“œí’€ì—ì„œ ì‹¤í–‰
    def _call():
        return client.chat.completions.create(
            model=model,
            messages=messages,
            temperature=0.4,
            max_tokens=350,
        )

    completion = await run_in_threadpool(_call)
    return (completion.choices[0].message.content or "").strip()

@router.post("/text", response_model=ChatResponse)
async def chat_text(body: ChatRequest):
    """
    í…ìŠ¤íŠ¸ ì±— ì—”ë“œí¬ì¸íŠ¸:
    - OPENAI_API_KEYê°€ ìˆìœ¼ë©´ OpenAIë¡œ ëª¨ë“  ì±„íŒ… ì²˜ë¦¬
    - í‚¤ê°€ ì—†ê±°ë‚˜ ì‹¤íŒ¨ ì‹œ, ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ í´ë°±
    - room_idë¥¼ ë„˜ê¸°ë©´ ìµœê·¼ ëª‡ í„´ì˜ ë§¥ë½ì„ ìœ ì§€
    """
    user_text = (body.text or "").strip()
    if not user_text:
        raise HTTPException(status_code=400, detail="text is required")

    # íˆìŠ¤í† ë¦¬ ê¸°ë¡(ìœ ì €)
    if body.room_id:
        _push_history(body.room_id, "user", user_text)

    # 1) OpenAI ì‚¬ìš© ê²½ë¡œ
    if _openai_available and OpenAI is not None:
        try:
            reply = await _llm_reply(user_text, body.room_id)
            # íˆìŠ¤í† ë¦¬ ê¸°ë¡(assistant)
            if body.room_id:
                _push_history(body.room_id, "assistant", reply)
            return ChatResponse(reply=reply)
        except Exception:
            # LLM ì‹¤íŒ¨ ì‹œ í´ë°±
            pass

    # 2) í´ë°± ê·œì¹™(í‚¤ ì—†ìŒ/ì‹¤íŒ¨)
    lower = user_text.lower()
    if any(k in lower for k in ["ë¬¼", "water", "ê¸‰ìˆ˜", "watering"]):
        return ChatResponse(reply="ê¸‰ìˆ˜ íŒ: í™ ìƒë‹¨ 2~3cmê°€ ë§ˆë¥´ë©´ ì¶©ë¶„íˆ ë¬¼ì„ ì£¼ì„¸ìš”. ë°°ìˆ˜êµ¬ê°€ ë§‰íˆì§€ ì•Šì•˜ëŠ”ì§€ë„ í™•ì¸í•˜ì„¸ìš”.")
    if any(k in lower for k in ["ë¹›", "sun", "light", "ê´‘ëŸ‰"]):
        return ChatResponse(reply="ê´‘ëŸ‰ íŒ: ëŒ€ë¶€ë¶„ì˜ ì‹¤ë‚´ ì‹ë¬¼ì€ ë°ì€ ê°„ì ‘ê´‘ì„ ì„ í˜¸í•´ìš”. ì§ì‚¬ê´‘ì„ ì€ ìì„ íƒœìš¸ ìˆ˜ ìˆì–´ìš”.")
    if any(k in lower for k in ["ë¹„ë£Œ", "ì˜ì–‘", "fertilizer"]):
        return ChatResponse(reply="ë¹„ë£Œ íŒ: ìƒì¥ê¸°(ë´„~ì—¬ë¦„)ì—” 4~6ì£¼ ê°„ê²©ì˜ í¬ì„ ë¹„ë£Œê°€ ì¢‹ì•„ìš”. ê²¨ìš¸ì—” ë¹ˆë„ë¥¼ ì¤„ì´ì„¸ìš”.")

    return ChatResponse(
        reply="ì‹ë¬¼ ê´€ë¦¬ì™€ ê´€ë ¨ëœ ì§ˆë¬¸ì„ í•˜ì‹œë©´ ë” êµ¬ì²´ì ìœ¼ë¡œ ë„ì™€ë“œë¦´ê²Œìš” ğŸŒ¿\n"
              "ì˜ˆ) 'ëª¬ìŠ¤í…Œë¼ ë¬¼ ì£¼ê¸°', 'ë¹›ì´ ë¶€ì¡±í•  ë•Œ ì¦ìƒ', 'ë¶„ê°ˆì´ ì‹œê¸°'"
    )
